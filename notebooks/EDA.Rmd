---
header-includes:
  - \usepackage{amsmath}
  - \usepackage{amssymb}
  - \usepackage{amsthm}
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
  - \fancyhead[CO,CE]{Hair Parra}
  - \fancyfoot[CO,CE]{Notes by Hair Parra}
  - \fancyfoot[LE,RO]{\thepage}
title: "Road Safety Pilot Project - EDA"
author: "Hair Albeiro Parra Barrera"
geometry: margin=1.3cm
always_allow_html: true
output: 
    pdf_document: 
      extra_dependencies: ["array", "amsmath","booktabs"]
---

\newtheorem{assumption}{Assumption}[assumption]
\newtheorem{theorem}{Theorem}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{example}{Example}
\newtheorem{remark*}{Remark}
\newtheorem{aside*}{Aside}
\newtheorem{exercise*}{Exercise}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=9, fig.height=6) 

# configurations for plot 
my_plot_hook <- function(x, options)
  paste("\n", knitr::hook_plot_tex(x, options), "\n")
knitr::knit_hooks$set(plot = my_plot_hook)
```

## Libraries 

```{r libraries, message=FALSE, warning=FALSE}
# CRAN libraries
library("sf") # temp
library("here")
library("tidyr")
library("dplyr")
library("tibble")
library("readxl")
library("corrplot")
library("lubridate")
library("ggmap") # temp 
library("ggplot2")
library("data.table")

# Custom scripts  
source(here("functions", "utils.R"))
source(here("functions", "clean_data.R"))
source(here("functions", "install_packages.R"))

# load packages if necessary 
f_load_packages()
```


# Exploratory Data Analysis 

## Data Cleaning 

```{r}
# Load data from the data_raw folder with UTF-8 encoding
dat <- read.csv(here("data_raw", "data_final.csv"), sep=";")
head(dat)
```

First, we extract some metadata. 

```{r}
# store the intersections id_no to rue_1 and rue_2 mapping
inter_names <- subset(dat, select = c(int_no, x, y, rue_1, rue_2))
inter_names
```

```{r}
# load the Dicionnaire_final object similar to before
varnames <- read_excel(here("data_raw","Dictionnaire_final.xlsx"))
varnames_dict <- setNames(as.list(varnames$DESCRIPTION), varnames$NOM)
names(varnames_dict) <- gsub("[^[:alnum:]_]+", "", names(varnames_dict)) # ensure clean list names
print(head(varnames_dict))
```

- We can observe a number of irrelevant columns (e.g. `street_1`, `street_2`, `X`, `X.1`) that we will remove.
- Also, the borough names contains typos, so we will also correct those to have consiten names.
- We also observersome covariates are of the wrong type (e.g. categorical, numerical, etc.)

## Preprocessing 

The function `f_clean_data` performs some basic data processing including NA cleaning, removing irrelevant columns, cleaning the borough names, inputation for `date_` and other basic transformations.

```{r}
# reload raw data 
dat <- read.csv(here("data_raw", "data_final.csv"), sep=";")

# perform data cleaning 
dat <- f_clean_data(dat)
```


The datatypes now are of the correct type for all variables: 

```{r}
str(dat)
```


The names of the boroughs have also been corrected: 

```{r}
unique(dat$borough)
```
### Covariates lists 

```{r}
# list all categorical covarariates 
categ_vars <- c("all_pedest", "median", "green_stra", "half_phase", "any_ped_pr", 
                "ped_countd", "lt_protect", "lt_restric", "lt_prot_re",
                "any_exclus", "parking", "curb_exten", "all_red_an", "new_half_r",
                "borough")

# list all numerical covariates 
num_vars <- c("fi", "fli", "fri", "fti", "cli",
              "cri", "cti", "acc", "ln_pi", "ln_fi", "ln_fli",
              "ln_fri", "ln_fti", "ln_cli", "ln_cri", "ln_cti",
              "tot_crossw", "number_of_", "avg_crossw", "tot_road_w", 
              "north_veh", "north_ped", "east_veh", "east_ped",
              "south_veh", "south_ped", "west_veh", "west_ped", 
              "total_lane", "of_exclusi", "commercial",
              "distdt", "ln_distdt", "traffic_10000", "ped_100")

# all covariates together 
all_vars <- c(categ_vars, num_vars)
```


### Dummy Variables 

```{r}
# version with dummy variables instead of factors
dat_dum <- f_convert_to_dummies(dat, all_vars)
head(dat_dum)
```

```{r}
head(dat)
```



## Correlation Analysis 

In order to determine whether the data is suitable for a regression analysis, we will perform a correlation analysis. 

### Numerical Covariates

```{r}
# Filter out 'ln_' prefixed variables from num_vars and ensure 'acc' is included
filtered_num_vars <- num_vars[!grepl("^ln_", num_vars) | num_vars == "acc"]

# Selecting only the correct numerical variables including 'acc'
numeric_dat <- dat %>%
               select(all_of(filtered_num_vars))

# Standardize the numerical data (becomes a matrix)
std_num_dat <- f_standardize_data(numeric_dat, auto=TRUE)

# Re-add the target variable 'acc' to the standardized data (matrix)
std_num_dat <- cbind(std_num_dat, dat$acc)
colnames(std_num_dat)[ncol(std_num_dat)] <- "acc"

# Compute the correlation matrix
cor_matrix <- cor(std_num_dat, use = "complete.obs", method="spearman")

# Convert the correlation matrix to a long format
cor_data <- as.data.frame(as.table(cor_matrix))

# Plotting the correlation matrix
ggplot(cor_data, aes(x = Var1, y = Var2, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(fill = "Correlation", x = "", y = "", title = "Correlation Matrix of Numerical Variables")
```

Since the correlation matrix is hard to understand, we look to focus our attention on the most 
linearly correlated covariates with the target variable `acc`. For this, we use three correlation metrics: Pearson, Spearman and Kendall. In particular, we use as a sorting criterion the Spearman correlation metric, which is the most robust to outliers.

```{r}
# Compute correlations
correlations_with_acc <- f_compute_correlations(dat, "acc", filtered_num_vars)

# Convert row names to a column
correlations_with_acc <- correlations_with_acc %>% rownames_to_column(var = "variable")

# Identifying the top 15 most positively and negatively correlated variables
top_n = 15
top_positively_correlated <- correlations_with_acc %>% 
                             arrange(desc(spearman)) %>%
                             head(top_n+1)

top_negatively_correlated <- correlations_with_acc %>% 
                             arrange(spearman) %>%
                             head(top_n+1)

# Filter out rows with negative correlation in positive correlated, and vice versa
top_positively_correlated <- top_positively_correlated[top_positively_correlated$spearman > 0, ]
top_negatively_correlated <- top_negatively_correlated[top_negatively_correlated$spearman < 0, ]

# filter the target variable out of the correlations 
top_positively_correlated <- top_positively_correlated[-1, ]
top_negatively_correlated <- top_negatively_correlated[-1, ]

# reset the index of both corr tables
rownames(top_positively_correlated) <- seq(1, nrow(top_positively_correlated))
rownames(top_negatively_correlated) <- seq(1, nrow(top_negatively_correlated))

# Add a column containing the description of the variables
top_positively_correlated$description <- sapply(top_positively_correlated$variable, 
                                                function(x) f_get_description(x, varnames_dict))
top_negatively_correlated$description <- sapply(top_negatively_correlated$variable, 
                                                function(x) f_get_description(x, varnames_dict))

# Convert the description column to a character vector if it's not already
top_positively_correlated$description <- as.character(top_positively_correlated$description)
top_negatively_correlated$description <- as.character(top_negatively_correlated$description)

# Presenting the tables
print(top_positively_correlated)
print(top_negatively_correlated)
```

## Visualizations 

Produce visualizations 

## Distribution of Accidents per Borough

**Question:** Which borough has the most accidents?

```{r, fig.width=11, fig.height=8}
# Calculate total accidents per borough
borough_accidents <- dat %>%
  group_by(borough) %>%
  summarize(total_accidents = sum(acc, na.rm = TRUE)) %>%
  arrange(desc(total_accidents))

# Calculate the median and mean number of accidents
median_accidents <- median(borough_accidents$total_accidents, na.rm = TRUE)
mean_accidents <- mean(borough_accidents$total_accidents, na.rm = TRUE)

# Bar Chart of Accidents by Borough using borough_accidents
ggplot(borough_accidents, aes(
    x = reorder(borough, -total_accidents),
    y = total_accidents
  )) +
  geom_bar(stat = "identity", aes(fill = total_accidents)) +
  geom_hline(yintercept = median_accidents, color = "red", linetype = "dashed", linewidth = 1) +
  geom_hline(yintercept = mean_accidents, color = "black", linetype = "dashed", linewidth = 1) +
  annotate("text", x = nrow(borough_accidents), y = median_accidents, 
           label = "Median", vjust = -1, color = "red") +
  annotate("text", x = nrow(borough_accidents), y = mean_accidents, 
           label = "Mean", vjust = -1, color = "black") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +  # Gradient of blues
  ggtitle("Number of Accidents by Borough") +
  xlab("Borough") +
  ylab("Number of Accidents") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1), 
    legend.position = "none"  # Remove legend and rotate labels
  )

```

## Aggregated Number of Accidents Month by Month (misleading)

```{r}
# Convert the date column to Date type
dat_plt <- dat %>% filter(!is.na(date_))  # Exclude rows with NA in date_plot

# Extract month part from the date (ignoring the year)
dat_plt$month_only <- format(dat_plt$date_, "%m")

# Calculate average accidents per month
average_monthly_accidents <- dat_plt %>%
  group_by(month_only) %>%
  summarise(average_accidents = mean(acc, na.rm = TRUE)) %>%
  arrange(month_only)

# Create a gradient of blues
blue_gradient <- scale_fill_gradient(low = "lightblue", high = "darkblue")

# Bar Chart of Average Accidents by Month with gradient fill
ggplot(average_monthly_accidents, aes(x = month_only, y = average_accidents, fill = average_accidents)) +
  geom_bar(stat = "identity") +
  ggtitle("Estimated Average Number of Accidents by Month") +
  xlab("Month") +
  ylab("Average Number of Accidents") +
  scale_x_discrete(labels = c('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec')) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  blue_gradient

rm(dat_plt); gc(); # Remove temporary data frame and run garbage collector
```

## Top and Bottom 10 Intersections with Most Accidents

```{r}
# Calculate total accidents per intersection
intersection_accidents <- dat %>%
  group_by(int_no, rue_1, rue_2) %>%
  summarise(total_accidents = sum(acc, na.rm = TRUE), .groups = 'drop') %>%
  arrange(desc(total_accidents))

# Extract the top 10 intersections
top_intersections <- head(intersection_accidents, 10)

# Create a factor variable for accident ranges
top_intersections$accident_range <- cut(top_intersections$total_accidents,
                                        breaks = quantile(top_intersections$total_accidents, 
                                                          probs = seq(0, 1, length.out = 5), na.rm = TRUE),
                                        include.lowest = TRUE, labels = FALSE)

# Plotting the top 20 intersections with gradient fill
ggplot(top_intersections, aes(x = reorder(paste(rue_1, rue_2), total_accidents), y = total_accidents, fill = factor(accident_range))) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Blues", direction = 1) +
  ggtitle("Top 20 Intersections with Most Accidents") +
  xlab("Intersection") +
  ylab("Number of Accidents") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none") +  # Remove the legend
  coord_flip()  # Flip coordinates for horizontal layout
```


## Cumulative Number of Boroughs through time (drop?)

```{r}
library(ggplot2)
library(dplyr)
library(lubridate)

# Convert the date column to Date type
dat$date_plot <- dmy(dat$date_)

# Arrange data by date
dat <- dat %>%
  arrange(date_plot)

# Calculate the cumulative number of accidents
dat$cumulative_acc <- cumsum(dat$acc)

# Plotting the cumulative number of accidents over time
ggplot(dat, aes(x = date_plot, y = cumulative_acc)) +
  geom_line() +
  labs(title = "Cumulative Number of Accidents Over Time",
       x = "Date",
       y = "Cumulative Accidents") +
  theme_minimal()
```
```{r, fig.width=11, fig.height=8}
# Calculate the cumulative number of accidents per borough
borough_accidents <- dat %>%
  group_by(borough, date_plot) %>%
  summarise(daily_acc = sum(acc), .groups = 'drop') %>%
  arrange(borough, date_plot) %>%
  group_by(borough) %>%

  mutate(cumulative_acc = cumsum(daily_acc))
# Plotting time series for each borough
ggplot(borough_accidents, aes(x = date_plot, y = cumulative_acc, color = borough)) +
  geom_line() +
  labs(title = "Cumulative Number of Accidents by Borough Over Time",
       x = "Date",
       y = "Cumulative Accidents",
       color = "Borough") +
  theme_minimal() +
  theme(legend.position = "bottom") + 
  guides(color = guide_legend(byrow = TRUE, ncol = 3))

```
```{r, fig.width=11, fig.height=12}
# Calculate the cumulative number of accidents per borough
borough_accidents <- dat %>%
  group_by(borough, date_plot) %>%
  summarise(daily_acc = sum(acc), .groups = 'drop') %>%
  arrange(borough, date_plot) %>%
  group_by(borough) %>%
  mutate(cumulative_acc = cumsum(daily_acc))

# Calculate the mean and median of cumulative accidents across boroughs for each date
borough_stats <- borough_accidents %>%
  group_by(date_plot) %>%
  summarise(mean_cumulative_acc = mean(cumulative_acc), 
            median_cumulative_acc = median(cumulative_acc))

# Plotting time series for each borough, with mean and median lines
ggplot() +
  geom_line(data = borough_accidents, aes(x = date_plot, y = cumulative_acc, color = borough)) +
  geom_line(data = borough_stats, aes(x = date_plot, y = mean_cumulative_acc), color = "black", linetype = "dashed") +
  # geom_line(data = borough_stats, aes(x = date_plot, y = median_cumulative_acc), color = "grey", linetype = "dotted") +
  labs(title = "Cumulative Number of Accidents by Borough Over Time",
       x = "Date",
       y = "Cumulative Accidents",
       color = "Borough") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  guides(color = guide_legend(byrow = TRUE, ncol = 3))

```








