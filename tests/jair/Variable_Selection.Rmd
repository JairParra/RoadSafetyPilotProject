---
title: "Road Safety Pilot Project - Variable Selection"
author: "Charles & Hair"
header-includes:
- \usepackage{amsmath}
- \usepackage{amssymb}
- \usepackage{amsthm}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhead[CO,CE]{Hair Parra}
- \fancyfoot[CO,CE]{Notes by Hair Parra}
- \fancyfoot[LE,RO]{\thepage}
output:
  html_document:
    df_print: paged
  pdf_document:
    extra_dependencies:
    - array
    - amsmath
    - booktabs
always_allow_html: true
geometry: margin=1.3cm
---

\newtheorem{assumption}{Assumption}[assumption]
\newtheorem{theorem}{Theorem}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{example}{Example}
\newtheorem{remark*}{Remark}
\newtheorem{aside*}{Aside}
\newtheorem{exercise*}{Exercise}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=9, fig.height=6) 

# configurations for plot 
my_plot_hook <- function(x, options)
  paste("\n", knitr::hook_plot_tex(x, options), "\n")
knitr::knit_hooks$set(plot = my_plot_hook)
```

## Libraries 

```{r libraries, message=FALSE, warning=FALSE}
# CRAN libraries
library("sf") # temp
library("here")
library("tidyr")
library("dplyr")
library("tibble")
library("readxl")
library("corrplot")
library("lubridate")
library("ggmap") # temp 
library("ggplot2")
library("data.table")
library("MASS")
library("glmnet")
library("caret")

#install.packages("forcats")
library(forcats)


# Custom scripts  
source(here("functions", "utils.R"))
source(here("functions", "clean_data.R"))
source(here("functions", "install_packages.R"))

# load packages if necessary 
#f_load_packages()
```

## Load the data 


```{r message=FALSE, warning=FALSE}
# Load the dataset and perform data cleaning 
dat <- read.csv(here("data_raw", "data_final.csv"), sep=";")
dat <- f_clean_data(dat)

# Load variable descriptors 
result <- f_load_varnames(here("data_raw", "Dictionnaire_final.xlsx"))
varnames <- result$varnames
varnames_dict <- result$varnames_dict

# preview dat 
head(dat)
```

- The variable `all_pedest` has very rare occurrence.
- The variable `number of` could be treated as categorical and is very unevenly distributed.
- The variables `traffic_10000 = fi`
- The variable `ped_100 = pi`

Visually, the `ln` transformation seem to make the relationship between predictors and target more linear.

```{r}
# Summary of the dataset
summary(dat)
```

```{r}
# Display frequency table for the 'number_of_' column
table(dat$number_of_)
```

```{r}
# Display frequency table for the 'all_pedest' column
table(dat$all_pedest)
```

```{r}
# Display frequency table for the 'borough_grouped' column
table(dat$borough_grouped)
```



```{r message=FALSE, warning=FALSE}

# Function to plot numerical variables against the target variable
plotNumericalVsTarget <- function(input_df, target_variable) {
  # Identify numerical columns in the input dataframe
  numerical_columns <- sapply(input_df, is.numeric)
  
  # Loop through each numerical column
  for (col in names(input_df)[numerical_columns]) {
    # Check if the current column is not the target variable
    if (col != target_variable) {
      # Print the current column name
      print(col)
      
      # Create a scatter plot for the current numerical column against the target variable
      c = ggplot(input_df, aes_string(x = col, y = target_variable)) +
        geom_point() +
        labs(title = paste(col, "vs", target_variable),
             x = col, y = target_variable)
      
      # Print the scatter plot
      print(c)
    }
  }
}

# Call the plotNumericalVsTarget function with the dataset 'dat' and target variable 'acc'
plotNumericalVsTarget(dat, "acc")

```

```{r message=FALSE, warning=FALSE}

# Check the frequency of each level in the 'borough' factor variable
borough_levels <- table(dat$borough)

# Identify levels with fewer than 30 observations
levels_to_group <- names(borough_levels[borough_levels < 50])

# Create a new factor with 'Other' level for levels with fewer than 30 observations
dat$borough_grouped <- fct_collapse(dat$borough, Other = levels_to_group)

# Print the updated 'borough' factor variable
cat("Original 'borough' factor variable:\n")
table(dat$borough)

cat("\n'borough' factor variable with 'Other' level:\n")
table(dat$borough_grouped)
```
# Variable Selection 

## Cross-validated MSE

```{r message=FALSE, warning=FALSE}
# Create a linear regression model using caret and perform cross-validation
ctrl <- trainControl(method = "cv", number = 10)
model <- train(acc ~., data = dat, method = "lm", trControl = ctrl)

# Print the cross-validated results
print(model)

# Show the resampled metrics: 
print(model$resample)
```


## Stepwise Selection

```{r message=FALSE, warning=FALSE}
# Create relevant interactions
initial_model <- lm(acc ~ . 
                    + month * cli
                    + month * cri
                    + month * cti
                    + month * ln_cli
                    + month * ln_cri
                    + month * ln_cti
                    + dow * cli
                    + dow * cri
                    + dow * cti
                    + dow * ln_cli
                    + dow * ln_cri
                    + dow * ln_cti
                    , data = dat)

#initial_model <- lm(acc ~ . , data = dat)

# Perform stepwise feature selection with interactions using AIC
final_model <- stepAIC(initial_model, trace=FALSE, direction = "both", k = log(nrow(dat)))

# Display the summary of the final model
summary(final_model)

# Best BIC found so far is 3576.66 using stepwise selection
# Final model:

#lm(formula = acc ~ x + fi + fri + cli + cti + ln_pi + ln_fri + 
#    ln_cri + ln_cti + tot_crossw + median + green_stra + half_phase + 
#    north_veh + commercial + ln_distdt + missing_date_ind + dow + 
#    parking + cti:dow, data = dat)
```

Performance measures collected were retrieved at a specfic time of the year. This may affect the impact of those variables. Create interaction.


## Lasso Variable Selection 

```{r message=FALSE, warning=FALSE}
# Combine the response and predictor variables into a matrix
X <- model.matrix(acc ~ ., data = dat)[, -1]  # RemoAve intercept column
y <- dat$acc

# Set up a Lasso model with cross-validation
lasso_cv_model <- cv.glmnet(X, y, alpha = 1)  # alpha = 1 for Lasso

# Plot the cross-validated mean squared error (CV MSE) as a function of log(lambda)
plot(lasso_cv_model)
```


```{r}
# Identify the lambda value that minimizes the CV MSE
best_lambda <- lasso_cv_model$lambda.min

cat("Selected Lambda (lambda.min):", lasso_cv_model$lambda.min, "\n")
cat("Cross-validated Mean Squared Error (CV MSE):", min(lasso_cv_model$cvm), "\n")

# Fit the final Lasso model with the selected lambda
final_lasso_model <- glmnet(X, y, alpha = 1, lambda = best_lambda)

# Extract coefficients from the final model
selected_features <- coef(final_lasso_model)

# Display the selected features
print(selected_features)

# MSE on cross validation is 6.7
```



## Group-Lasso 


$$
\begin{aligned}
\hat{\beta} &= \arg\min_{\beta} \left\{ \sum_{i=1}^{n} (y_i - (\beta_0 + \beta^T x_i))^2 + \lambda \sum_{\ell=1}^{L} \sqrt{p_{\ell}} \left( \sum_{j \in G_{\ell}} \beta_j^2 \right)^{\frac{1}{2}}   \right\} 
\end{aligned}
$$


```{r}
# Reload the data and perform cleaning
dat_orig <- read.csv(here("data_raw", "data_final.csv"), sep=";")

# Clean the data
dat <- f_clean_data(dat_orig, 
                    group_boroughs = TRUE, 
                    drop_borough=TRUE, 
                    drop_year=TRUE, 
                    standarize = TRUE,
                    numerical_categories = FALSE) # integer-based values

# Drop the raw data object 
rm(dat_orig); gc(verbose=FALSE);

## Create an additional version which contains dummies instead of factors 

# All the variables should go into the dummies, except `acc`
all_vars <- setdiff(colnames(dat), "acc")

# Create a version with dummies
dat_dum <- f_convert_to_dummies(dat, all_vars)

# Reassign the target variable
target <- dat$acc

# Preview the data
head(dat_dum)
```

```{r}
paste(colnames(dat_dum))
```


```{r}
# Redefine the 'group' vector for grpreg based on the updated structure of dat_dum
group <- c(
  1:45,                 # Variables 1 to 45 are individual
  rep(46, 2),           # Variables 46 and 47 for 'parking'
  48:52,                # Variables 48 to 52 are individual
  rep(53, 11),          # Variables 53 to 63 for 'month'
  rep(64, 6),           # Variables 64 to 69 for 'dow'
  rep(70, 12)           # Variables 70 to 81 for 'borough'
)

# Note: Adjust the last group number based on actual variable indices if necessary

# Continue with your existing code for fitting the group lasso model
set.seed(14273)  # Ensure reproducibility

# Assuming 'dat_dum' is your predictors and 'target' is your response variable
# Fit a group lasso regression model using the corrected 'group' vector
grlassofit <- grpreg(X = dat_dum, y = target, group = group, penalty = "grLasso")

# Plot the results
plot(grlassofit)
```
```{r}
coef(grlassofit, s = 0.5)
```



